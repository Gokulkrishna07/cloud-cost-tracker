# Cloud Cost Overrun Prediction System - Walkthrough

## Overview
I have built a production-grade ML system to predict cloud costs and detect budget overruns. The system includes:
- **Synthetic Data Generation**: Simulates realistic cloud usage patterns (EC2, Storage, Data Transfer).
- **Model Training**: A RandomForestRegressor pipeline with MLflow tracking.
- **Inference API**: FastAPI service serving predictions with Prometheus metrics.
- **MLOps**: Drift detection module and GitHub Actions for CI/CD.
- **Monitoring**: Docker Compose setup for MLflow, Prometheus, and Grafana.

## Components

### 1. Data Pipeline
- [data/generate_synthetic_data.py](file:///h:/AI-ML/cloud-cost-mlops/data/generate_synthetic_data.py): Generates historical usage data.
- [data/schema/validation.py](file:///h:/AI-ML/cloud-cost-mlops/data/schema/validation.py): Pydantic and Pandera schemas for data validation.

### 2.{
  "project_name": "Cloud Cost Overrun Prediction System",
  "objective": "Build a production-grade ML + MLOps system that predicts daily cloud infrastructure cost and proactively detects budget overruns, with automated retraining and deployment.",
  "problem_statement": "Given historical daily cloud usage metrics, predict future daily cloud cost and trigger alerts when predicted usage exceeds a defined budget.",
  "data_source_strategy": {
    "initial_phase": "Statistically controlled synthetic dataset simulating real-world cloud usage patterns",
    "production_phase": "AWS Cost Explorer API (daily aggregated billing data)",
    "data_granularity": "Daily",
    "data_retention_policy": "Append-only, immutable historical records"
  },
  "input_features": [
    {
      "name": "ec2_hours",
      "type": "float",
      "description": "Total EC2 compute hours used in a day"
    },
    {
      "name": "storage_gb",
      "type": "float",
      "description": "Average storage consumed in GB"
    },
    {
      "name": "data_transfer_gb",
      "type": "float",
      "description": "Outbound data transfer in GB"
    },
    {
      "name": "rds_usage",
      "type": "float",
      "description": "Relational database usage units"
    },
    {
      "name": "lambda_invocations",
      "type": "integer",
      "description": "Number of AWS Lambda invocations"
    }
  ],
  "target_variable": {
    "name": "daily_cost",
    "type": "float",
    "description": "Total cloud infrastructure cost for the day"
  },
  "feature_engineering": [
    "Previous day cost (lag_1)",
    "3-day rolling average cost",
    "7-day rolling average cost",
    "Weekend/weekday indicator"
  ],
  "machine_learning_model": {
    "algorithm": "RandomForestRegressor",
    "reason": "Handles non-linearity, stable with limited data, CPU-friendly",
    "evaluation_metrics": [
      "MAE",
      "RMSE"
    ],
    "model_registry": "MLflow"
  },
  "training_pipeline": {
    "steps": [
      "Validate input data schema",
      "Perform feature engineering",
      "Train regression model",
      "Evaluate against validation set",
      "Log metrics and artifacts to MLflow",
      "Register model version"
    ],
    "minimum_training_data_days": 90
  },
  "inference_api": {
    "framework": "FastAPI",
    "endpoints": {
      "/predict": {
        "method": "POST",
        "input_contract": {
          "ec2_hours": "float",
          "storage_gb": "float",
          "data_transfer_gb": "float",
          "rds_usage": "float",
          "lambda_invocations": "integer",
          "budget": "float"
        },
        "output_contract": {
          "predicted_cost": "float",
          "budget": "float",
          "overrun": "boolean",
          "risk_level": "LOW | MEDIUM | HIGH",
          "model_version": "string",
          "timestamp": "ISO-8601"
        }
      },
      "/health": {
        "method": "GET",
        "description": "Service and model health check"
      }
    }
  },
  "business_rules": {
    "budget_overrun_logic": "If predicted_cost > budget then overrun = true",
    "risk_levels": {
      "LOW": "< 80% of budget",
      "MEDIUM": "80% - 100% of budget",
      "HIGH": "> 100% of budget"
    }
  },
  "monitoring_and_observability": {
    "metrics": [
      "prediction_requests_total",
      "predicted_cost_average",
      "budget_overrun_count",
      "model_version",
      "prediction_latency_ms"
    ],
    "tools": [
      "Prometheus",
      "Grafana"
    ],
    "drift_detection": {
      "inputs": [
        "Recent feature distributions",
        "Prediction vs actual cost"
      ],
      "output": {
        "drift_detected": "boolean",
        "severity": "LOW | MEDIUM | HIGH"
      }
    }
  },
  "auto_retraining": {
    "triggers": [
      "New data volume >= 7 days",
      "Model error exceeds threshold",
      "Feature drift detected"
    ],
    "validation_rule": "New model RMSE must improve by at least 5% over current production model",
    "deployment_strategy": "Promote via MLflow Model Registry and redeploy API automatically"
  },
  "deployment": {
    "containerization": "Docker",
    "ci_cd": "GitHub Actions",
    "pipelines": [
      "Training pipeline",
      "Deployment pipeline",
      "Retraining pipeline"
    ]
  },
  "project_structure": {
    "data": ["raw", "processed", "schema"],
    "training": ["data_loader", "feature_engineering", "train", "evaluate"],
    "api": ["routes", "schemas", "main"],
    "monitoring": ["metrics", "drift", "alerts"],
    "retraining": ["trigger", "validator", "promotion"]
  },
  "expected_outputs": [
    "Daily cloud cost prediction",
    "Budget overrun alerts",
    "Model performance dashboards",
    "Automated retraining and redeployment"
  ],
  "resume_summary": "Designed and implemented a production-grade MLOps system to predict cloud infrastructure costs, detect budget overruns, and automatically retrain and redeploy models using CI/CD, MLflow, FastAPI, Docker, Prometheus, and Grafana."
}
 Model Training
- [training/train.py](file:///h:/AI-ML/cloud-cost-mlops/training/train.py): Loads data, performs feature engineering (lags, rolling stats), trains the model, and logs artifacts to MLflow.
- **Run Training**:
  ```bash
  python training/train.py
  ```

### 3. Inference API
- [api/main.py](file:///h:/AI-ML/cloud-cost-mlops/api/main.py): FastAPI app with `/predict` endpoint.
- **Run API Locally**:
  ```bash
  uvicorn api.main:app --reload
  ```
- **Example Request**:
  ```bash
  curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{
    "ec2_hours": 100,
    "storage_gb": 500,
    "data_transfer_gb": 20,
    "rds_usage": 50,
    "lambda_invocations": 1000,
    "budget": 80.0
  }'
  ```

### 4. MLOps & Monitoring
- **Drift Detection**: [monitoring/drift/detect.py](file:///h:/AI-ML/cloud-cost-mlops/monitoring/drift/detect.py) implements KS-test based drift detection.
- **Infrastructure**: Run the full stack with Docker Compose.
  ```bash
  docker-compose up -d
  ```
  - **MLflow**: http://localhost:5000
  - **Prometheus**: http://localhost:9090
  - **Grafana**: http://localhost:3000
  - **API**: http://localhost:8000

## Verification Results
- **Data**: Verified synthetic data generation (Sample created in [data/raw/cloud_cost_data.csv](file:///h:/AI-ML/cloud-cost-mlops/data/raw/cloud_cost_data.csv)).
- **Code**: Implemented and validated python scripts for training and API.
- **CI/CD**: Created [.github/workflows/training.yml](file:///h:/AI-ML/cloud-cost-mlops/.github/workflows/training.yml) and [deploy.yml](file:///h:/AI-ML/cloud-cost-mlops/.github/workflows/deploy.yml).

> [!NOTE]
> Ensure Docker is running before starting the services.
